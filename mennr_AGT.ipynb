{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Mennr-AutoGPT"
      ],
      "metadata": {
        "id": "EiLypFoO-LCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Significant-Gravitas/Auto-GPT.git\n",
        "%cd /content/Auto-GPT\n",
        "!pip install -r requirements.txt -qq\n",
        "!mv .env.template env.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAjQQZq7-x69",
        "outputId": "1ec6deb4-6e45-4ffb-bbc9-5f5154004fea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Auto-GPT' already exists and is not an empty directory.\n",
            "/content/Auto-GPT\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.1/241.1 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m979.3/979.3 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.8/201.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.7/228.7 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.8/202.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.8/240.8 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.7/103.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.2/400.2 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.6/323.6 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.8/98.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.8/97.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for auto-gpt-plugin-template (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for vcrpy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps to follow now:\n",
        "1. Edit the env file with your openAI api key\n",
        "2. Run the cells below to run auto-gpt ;)\n",
        "\n"
      ],
      "metadata": {
        "id": "2FgSAIs__qZd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8lwmANijJi2",
        "outputId": "26306fb3-86e3-4bb9-a1c0-1c3fe07997d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               Title  \\\n",
            "0                              Aryan Garg | LinkedIn   \n",
            "1              200+ \"Aryan Garg\" profiles | LinkedIn   \n",
            "2                 Analyzing the Robustness of PECNet   \n",
            "3                            Renu M. Rameshan - dblp   \n",
            "4  Neelotpal Dutta - The University of Manchester...   \n",
            "5  Joshua Dickison - Copyright Officer - Univeris...   \n",
            "6  Yuvraj Misra on LinkedIn: Dear Connections, I ...   \n",
            "7  Jean-Francois Lalonde - Full Professor - Unive...   \n",
            "8  David Bomke – Köln, Nordrhein-Westfalen, Deuts...   \n",
            "9  Pieter Dockx - Architect - Architects in Motio...   \n",
            "\n",
            "                                                Link  \\\n",
            "0    https://in.linkedin.com/in/aryan-garg-ba511819b   \n",
            "1        https://www.linkedin.com/pub/dir/Aryan/Garg   \n",
            "2                   https://arxiv.org/pdf/2210.09846   \n",
            "3                      https://dblp.org/pid/81/10698   \n",
            "4         https://uk.linkedin.com/in/neelotpal-dutta   \n",
            "5  https://ca.linkedin.com/in/joshua-dickison-6ba...   \n",
            "6  https://ug.linkedin.com/posts/yuvrajmisra_dear...   \n",
            "7  https://ca.linkedin.com/in/jean-francois-lalon...   \n",
            "8   https://de.linkedin.com/in/david-bomke-6b720b1a5   \n",
            "9  https://be.linkedin.com/in/pieter-dockx-3705b416b   \n",
            "\n",
            "                                             Snippet  \n",
            "0  Aryan Garg. RA @ CILAB, IIT Madras + Image Sci...  \n",
            "1  Aryan Garg. RA @ CILAB, IIT Madras + Image Sci...  \n",
            "2  Oct 15, 2022 ... Aryan Garg. Indian Institute ...  \n",
            "3  Mar 26, 2023 ... Aryan Garg, Renu M. Rameshan:...  \n",
            "4  and Gold Medalist @ IIT Mandi (2020). FurrbleT...  \n",
            "5  Aryan Garg. RA @ CILAB, IIT Madras + Image Sci...  \n",
            "6  ... MS ECE @ UIUC | Quantum Science, Machine L...  \n",
            "7  Aryan Garg. RA @ CILAB, IIT Madras + Image Sci...  \n",
            "8  Aryan Goyal. SDE @AIW | Ex - Amazon Intern | E...  \n",
            "9  Aryan Garg. RA @ CILAB, IIT Madras + Image Sci...  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-522e3b8d28db>:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'Title': title, 'Link': link, 'Snippet': snippet}, ignore_index=True)\n",
            "<ipython-input-7-522e3b8d28db>:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'Title': title, 'Link': link, 'Snippet': snippet}, ignore_index=True)\n",
            "<ipython-input-7-522e3b8d28db>:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'Title': title, 'Link': link, 'Snippet': snippet}, ignore_index=True)\n",
            "<ipython-input-7-522e3b8d28db>:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'Title': title, 'Link': link, 'Snippet': snippet}, ignore_index=True)\n",
            "<ipython-input-7-522e3b8d28db>:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'Title': title, 'Link': link, 'Snippet': snippet}, ignore_index=True)\n",
            "<ipython-input-7-522e3b8d28db>:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'Title': title, 'Link': link, 'Snippet': snippet}, ignore_index=True)\n",
            "<ipython-input-7-522e3b8d28db>:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'Title': title, 'Link': link, 'Snippet': snippet}, ignore_index=True)\n",
            "<ipython-input-7-522e3b8d28db>:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'Title': title, 'Link': link, 'Snippet': snippet}, ignore_index=True)\n",
            "<ipython-input-7-522e3b8d28db>:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'Title': title, 'Link': link, 'Snippet': snippet}, ignore_index=True)\n",
            "<ipython-input-7-522e3b8d28db>:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'Title': title, 'Link': link, 'Snippet': snippet}, ignore_index=True)\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "api_key = \"AIzaSyBTZDeWsKdn_nTkoNkuzL688_hmRsWCRV8\"\n",
        "cx = \"a7a4933f0f79d4cb4\"\n",
        "query = \"Who is Aryan Garg from IIT Mandi?\"\n",
        "\n",
        "url = f\"https://www.googleapis.com/customsearch/v1?key={api_key}&cx={cx}&q={query}\"\n",
        "response = requests.get(url)\n",
        "data = json.loads(response.text)\n",
        "\n",
        "# Check for errors or empty search results\n",
        "if 'error' in data:\n",
        "    print(\"Error:\", data['error']['message'])\n",
        "elif 'items' not in data:\n",
        "    print(\"No search results found.\")\n",
        "else:\n",
        "    # Extract search results\n",
        "    search_results = data['items']\n",
        "\n",
        "    # Create a pandas DataFrame\n",
        "    columns = ['Title', 'Link', 'Snippet']\n",
        "    df = pd.DataFrame(columns=columns)\n",
        "\n",
        "    for result in search_results:\n",
        "        title = result['title']\n",
        "        link = result['link']\n",
        "        snippet = result['snippet']\n",
        "        df = df.append({'Title': title, 'Link': link, 'Snippet': snippet}, ignore_index=True)\n",
        "\n",
        "    # Display the DataFrame\n",
        "    print(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv env.txt .env\n",
        "!python -m autogpt -b \"https://www.googleapis.com/customsearch/v1?key={api_key}&cx={cx}\" --ai-name mennr-GPT --ai-role \"Help teachers and students accelerate learning\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK6sMMfC_p5k",
        "outputId": "f5da5746-95cc-477c-e6cf-bfc30dde8ce7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'env.txt': No such file or directory\n",
            "2023-07-25 17:34:38.347402: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-25 17:34:40.317253: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[33mWARNING: \u001b[0m You do not have access to gpt-4. Setting smart_llm to gpt-3.5-turbo.\n",
            "\u001b[32mNEWS: \u001b[0m \u001b[33mWelcome to Auto-GPT!\u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m Below you'll find the latest Auto-GPT News and updates regarding features!\u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m If you don't wish to see this message, you can run Auto-GPT with the \u001b[1m--skip-news\u001b[22m flag.\u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m \u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m \u001b[1m\u001b[36mQUICK LINKS 🔗\u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m \u001b[1m\u001b[36m--------------\u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m 🌎 \u001b[1mOfficial Website\u001b[22m: https://agpt.co.\u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m 📖 \u001b[1mUser Guide\u001b[22m: https://docs.agpt.co.\u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m 👩 \u001b[1mContributors Wiki\u001b[22m: https://github.com/Significant-Gravitas/Auto-GPT/wiki/Contributing.\u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m \u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m \u001b[1m\u001b[36mv0.4.5 RELEASE HIGHLIGHTS! 🚀\u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m \u001b[1m\u001b[36m-----------------------------\u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m This release includes under-the-hood improvements and bug fixes, such as more \u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m accurate token counts for OpenAI functions, faster CI builds, improved plugin \u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m handling, and refactoring of the Config class for better maintainability.\u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m \u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m We have also released some documentation updates, including:\u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m \u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m - \u001b[1mHow to share your system logs\u001b[22m\u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m   Visit [docs/share-your-logs.md] to learn how to how to share logs with us \u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m   via a log analyzer graciously contributed by https://www.e2b.dev/\u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m \u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m - \u001b[1mAuto-GPT re-architecture documentation\u001b[22m\u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m   You can learn more about the inner-workings of the Auto-GPT re-architecture \u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m   released last cycle, via these links:\u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m   * [autogpt/core/README.md]\u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m   * [autogpt/core/ARCHITECTURE_NOTES.md]\u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m \u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m Take a look at the Release Notes on Github for the full changelog! \u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m https://github.com/Significant-Gravitas/Auto-GPT/releases.\u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m \u001b[0m\n",
            "\u001b[31mWARNING: \u001b[0m You are running on `master` branch - this is not a supported branch.\n",
            "\u001b[32mWelcome to Auto-GPT! \u001b[0m run with '--help' for more information.\n",
            "\u001b[32mCreate an AI-Assistant: \u001b[0m input '--manual' to enter manual mode.\n",
            " \u001b[0m Asking user via keyboard...\n",
            "\u001b[6n\u001b[?2004h\u001b[?1l\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;94mI want Auto-GPT to\u001b[0m:\u001b[19D\u001b[20C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[20D\u001b[J\u001b[0m\u001b[?7h\u001b[?2004lWARNING: your terminal doesn't support cursor position requests (CPR).\n",
            "\u001b[?2004h\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;94mI want Auto-GPT to\u001b[0m:\u001b[19D\u001b[20C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?25l\u001b[?7l\u001b[0mHelp students with learning algebra\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?25l\u001b[?7l\u001b[55D\u001b[0m\u001b[J\u001b[0;94mI want Auto-GPT to\u001b[0m: Help students with learning algebra\u001b[55D\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\u001b[31mUnable to automatically generate AI Config based on user desire. \u001b[0m Falling back to manual mode.\n",
            "\u001b[32mCreate an AI-Assistant: \u001b[0m Enter the name of your AI and its role below. Entering nothing will load defaults.\n",
            "\u001b[32mName your AI: \u001b[0m For example, 'Entrepreneur-GPT'\n",
            " \u001b[0m Asking user via keyboard...\n",
            "\u001b[?2004h\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0mAI Name:\u001b[8D\u001b[9C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?25l\u001b[?7l\u001b[9D\u001b[0m\u001b[J\u001b[0mAI Name: mennr-GPT\u001b[18D\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\u001b[94mmennr-GPT here! \u001b[0m I am at your service.\n",
            "\u001b[32mDescribe your AI's role: \u001b[0m For example, 'an AI designed to autonomously develop and run businesses with the sole goal of increasing your net worth.'\n",
            " \u001b[0m Asking user via keyboard...\n",
            "\u001b[?2004h\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0mmennr-GPT is:\u001b[13D\u001b[14C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?25l\u001b[?7l\u001b[14D\u001b[0m\u001b[J\u001b[0mmennr-GPT is: Increase learning pace\u001b[36D\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\u001b[32mEnter up to 5 goals for your AI: \u001b[0m For example: Increase net worth, Grow Twitter Account, Develop and manage multiple businesses autonomously'\n",
            " \u001b[0m Enter nothing to load defaults, enter nothing when finished.\n",
            " \u001b[0m Asking user via keyboard...\n",
            "\u001b[?2004h\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;94mGoal\u001b[0m 1:\u001b[7D\u001b[8C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?25l\u001b[?7l\u001b[8D\u001b[0m\u001b[J\u001b[0;94mGoal\u001b[0m 1: Increase depth of understanding\u001b[39D\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l \u001b[0m Asking user via keyboard...\n",
            "\u001b[?2004h\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;94mGoal\u001b[0m 2:\u001b[7D\u001b[8C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?25l\u001b[?7l\u001b[0mIncrease pace of learning\u001b[C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?25l\u001b[?7l\u001b[34D\u001b[0m\u001b[J\u001b[0;94mGoal\u001b[0m 2: Increase pace of learning\u001b[33D\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l \u001b[0m Asking user via keyboard...\n",
            "\u001b[?2004h\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;94mGoal\u001b[0m 3:\u001b[7D\u001b[8C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?25l\u001b[?7l\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?25l\u001b[?7l\u001b[8D\u001b[0m\u001b[J\u001b[0;94mGoal\u001b[0m 3: Collaborate effectively\u001b[31D\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l \u001b[0m Asking user via keyboard...\n",
            "\u001b[?2004h\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;94mGoal\u001b[0m 4:\u001b[7D\u001b[8C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?25l\u001b[?7l\u001b[8D\u001b[0m\u001b[J\u001b[0;94mGoal\u001b[0m 4: Get personalized tests\u001b[30D\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l \u001b[0m Asking user via keyboard...\n",
            "\u001b[?2004h\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;94mGoal\u001b[0m 5:\u001b[7D\u001b[8C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?25l\u001b[?7l\u001b[8D\u001b[0m\u001b[J\u001b[0;94mGoal\u001b[0m 5: Get personalized feedback\u001b[33D\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\u001b[32mEnter your budget for API calls: \u001b[0m For example: $1.50\n",
            " \u001b[0m Enter nothing to let the AI run without monetary limit\n",
            " \u001b[0m Asking user via keyboard...\n",
            "\u001b[?2004h\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;94mBudget\u001b[0m: $\u001b[9D\u001b[9C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?25l\u001b[?7l\u001b[9D\u001b[0m\u001b[J\u001b[0;94mBudget\u001b[0m: $\u001b[9D\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\u001b[33mNOTE:All files/directories created by this agent can be found inside its workspace at: \u001b[0m /content/Auto-GPT/autogpt/auto_gpt_workspace\n",
            "\u001b[94mmennr-GPT \u001b[0m has been created with the following details:\n",
            "\u001b[32mName: \u001b[0m mennr-GPT\n",
            "\u001b[32mRole: \u001b[0m Increase learning pace\n",
            "\u001b[32mGoals: \u001b[0m\n",
            "\u001b[32m- \u001b[0m Increase depth of understanding\n",
            "\u001b[32m- \u001b[0m Increase pace of learning\n",
            "\u001b[32m- \u001b[0m Collaborate effectively\n",
            "\u001b[32m- \u001b[0m Get personalized tests\n",
            "\u001b[32m- \u001b[0m Get personalized feedback\n",
            "\u001b[32mUsing memory of type: \u001b[0m JSONFileMemory\n",
            "\u001b[32mUsing Browser: \u001b[0m https://www.googleapis.com/customsearch/v1?key=AIzaSyBTZDeWsKdn_nTkoNkuzL688_hmRsWCRV8&cx=a7a4933f0f79d4cb4\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/Auto-GPT/autogpt/__main__.py\", line 5, in <module>\n",
            "    autogpt.app.cli.main()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1078, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1666, in invoke\n",
            "    rv = super().invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/decorators.py\", line 33, in new_func\n",
            "    return f(get_current_context(), *args, **kwargs)\n",
            "  File \"/content/Auto-GPT/autogpt/app/cli.py\", line 118, in main\n",
            "    run_auto_gpt(\n",
            "  File \"/content/Auto-GPT/autogpt/app/main.py\", line 201, in run_auto_gpt\n",
            "    run_interaction_loop(agent)\n",
            "  File \"/content/Auto-GPT/autogpt/app/main.py\", line 282, in run_interaction_loop\n",
            "    command_name, command_args, assistant_reply_dict = agent.think()\n",
            "  File \"/content/Auto-GPT/autogpt/agents/base.py\", line 108, in think\n",
            "    raw_response = create_chat_completion(\n",
            "  File \"/content/Auto-GPT/autogpt/llm/utils/__init__.py\", line 157, in create_chat_completion\n",
            "    response = iopenai.create_chat_completion(\n",
            "  File \"/content/Auto-GPT/autogpt/llm/providers/openai.py\", line 147, in metered_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/Auto-GPT/autogpt/llm/providers/openai.py\", line 182, in _wrapped\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/Auto-GPT/autogpt/llm/providers/openai.py\", line 231, in create_chat_completion\n",
            "    completion: OpenAIObject = openai.ChatCompletion.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 298, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.RateLimitError: You exceeded your current quota, please check your plan and billing details.\n"
          ]
        }
      ]
    }
  ]
}